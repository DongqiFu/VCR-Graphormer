# VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections, ICLR 2024

![pic](/poster.png)


## How to run

1. Place datasets into "dataset" folder
   * Reddit, Aminer, and Amazon2M are [here](https://drive.google.com/drive/folders/1I_QGjMEc5ZjW8UpDfdz4mp6K0UggGkca?usp=sharing), they can also be traced from the original source [here](https://github.com/THUDM/GRAND-plus).
   * Squirrel and Actor are [here](https://drive.google.com/drive/folders/1I_QGjMEc5ZjW8UpDfdz4mp6K0UggGkca?usp=sharing), they can also be traced from the [DGL](https://docs.dgl.ai/en/2.0.x/api/python/dgl.data.html).
   * Other datasets are built in the library and can be directly accessed through our code.

2. Commands are in "demo.txt"

3. Dependencies are in "environment.yml"

## Codebase Acknowledgment
1. [NAGphormer: A Tokenized Graph Transformer for Node Classification in Large Graphs](https://github.com/JHL-HUST/NAGphormer)
2. [Influence-Based Mini-Batching for Graph Neural Networks](https://github.com/TUM-DAML/ibmb)
3. [GRAND+: Scalable Graph Random Neural Networks](https://github.com/THUDM/GRAND-plus)
4. [Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods](https://github.com/CUAI/Non-Homophily-Large-Scale)
